# -*- coding: utf-8 -*-
"""USL_SSL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HMYk7sHJ7H3gc0M1pWsWuRBTNTQfTCjn
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import sys
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from itertools import product
import pyarrow.parquet as pq

import torch
from sklearn.cluster import KMeans
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from sklearn.metrics import pairwise_distances_argmin_min
from scipy.spatial.distance import cdist

from sklearn.decomposition import PCA
import torch.nn.functional as F

from torch import nn
from torch.utils.data import TensorDataset, DataLoader
from torch.optim import Adam
from itertools import cycle

from google.colab import data_table
from vega_datasets import data

data_table.enable_dataframe_formatter()

os.chdir('/content/drive/MyDrive/Colab Notebooks/BA/data')

import pickle

# Replace 'your_file.pkl' with the path to your actual pickle file
file_path = 'df_trained_embeddings.pkl'

# Open the file in binary read mode
with open(file_path, 'rb') as file:
    # Load the content of the file into a Python object
    data = pickle.load(file)

# data.to_parquet('data.parquet')

"""# Visualization"""

data.columns

#  data = {'Name': ['Shuaib', 'Musa', 'Rhayor', 'Shebanky', 'Yusuf', 'Everlasting', 'Mary'],

# 'Age': [20, 21, 22, 23, 24, 25, 26],

# 'Country': ['NGN', 'NGN', 'NGN', 'NGN', 'UK', 'NGN', 'NGN']

# }

# df = pd.DataFrame(data)

# # Now, display the dataframe

# df

pd.set_option('display.max_columns', None)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('max_colwidth', None)
pd.options.display.max_rows = 10
data

data.top_domain

# Now you can use the 'data' variable, which contains your Python object
data.visual_embedding

# Assuming df is your DataFrame
df = data.copy(deep=True)

for col in df.columns:
    if any(isinstance(x, (list, np.ndarray)) for x in df[col]):
        print(f"Column '{col}' contains mutable types.")

# Set the style of seaborn
sns.set(style="whitegrid")

# List of columns to plot
columns_to_plot = [
    'Country', 'status', 'Municipality Website', 'data_source', 'top_domain',
    'handlabeled', 'y', 'dataset', 'markuplm_embedding_base_trained_predictions',
    'markuplm_embedding_large_trained_predictions', 'visual_embedding_trained_predictions',
    'homepage2vec_embedding_trained_predictions', 'homepage2vec_withvisual_embedding_trained_predictions',
    'header_embedding_trained_predictions'
]

# Plotting
for col in columns_to_plot:
    plt.figure(figsize=(10, 6))
    total = float(len(df))  # for calculating percentages for annotations
    ax = sns.countplot(x=col, data=df, palette='coolwarm')
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45, ha="right")

    # Add annotations
    for p in ax.patches:
        height = p.get_height()
        ax.text(p.get_x()+p.get_width()/2.,
                height + 3,
                '{:1.2f}%'.format(100*height/total),
                ha="center")

    plt.tight_layout()
    plt.show()

# Exclude embedding columns from the nunique operation
exclude_columns = [
    'basic_embedding', 'homepage2vec_embedding', 'homepage2vec_withvisual_embedding',
    'header_embedding', 'markuplm_embedding_base', 'markuplm_embedding_large',
    'basic_and_header_embedding', 'markuplm_embedding_base_trained_embedding',
    'markuplm_embedding_large_trained_embedding', 'visual_embedding_trained_embedding',
    'homepage2vec_embedding_trained_embedding', 'homepage2vec_withvisual_embedding_trained_embedding',
    'header_embedding_trained_embedding','visual_embedding'
]

# 1. Number of unique values in each column
scalar_columns = df.drop(columns=exclude_columns)
unique_values_scalar = scalar_columns.nunique()
print("Number of unique values in each scalar column:")
print(unique_values_scalar.to_string())

# 2. Number of NA values in each column
na_values = scalar_columns.isna().sum()
print("Number of NA values in each column:")
print(na_values.to_string())

# 3. Number of duplicate rows
duplicates = scalar_columns.duplicated().sum()
print(f"Number of duplicate rows in the DataFrame: {duplicates}")

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Define your DataFrame 'df' here
# df = pd.read_csv('your_file.csv')

fine_tuned_embedding_columns = [
    'markuplm_embedding_base_trained_embedding',
    'markuplm_embedding_large_trained_embedding',
    'visual_embedding_trained_embedding',
    'homepage2vec_embedding_trained_embedding',
    'homepage2vec_withvisual_embedding_trained_embedding',
    'header_embedding_trained_embedding'
]

prediction_of_fine_tuned_embedding_columns = [
    'markuplm_embedding_base_trained_predictions',
    'markuplm_embedding_large_trained_predictions',
    'visual_embedding_trained_predictions',
    'homepage2vec_embedding_trained_predictions',
    'homepage2vec_withvisual_embedding_trained_predictions',
    'header_embedding_trained_predictions'
]

original_label = 'y'

# Iterate over embedding columns and their corresponding prediction columns
for embedding_column, prediction_column in zip(fine_tuned_embedding_columns, prediction_of_fine_tuned_embedding_columns):
    print("t_SNE for the following embedding: ",embedding_column)
    embeddings = np.array(df[embedding_column].tolist())

    # PCA for dimensionality reduction
    pca = PCA(n_components=50)  # Reduce to 50 dimensions for faster t-SNE computation
    pca_result = pca.fit_transform(embeddings)

    # t-SNE for visualization
    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
    tsne_results = tsne.fit_transform(pca_result)

    # Prepare plot
    plt.figure(figsize=(16,10))
    for label in [0, 1]:
        for pred in [0, 1]:
            # Filter data points by actual label and predicted label
            idx = (df[original_label] == label) & (df[prediction_column] == pred)
            plt.scatter(tsne_results[idx, 0], tsne_results[idx, 1], label=f'Label: {label}, Pred: {pred}', alpha=0.5)

    plt.title(f't-SNE visualization of {embedding_column}')
    plt.xlabel('t-SNE axis 1')
    plt.ylabel('t-SNE axis 2')
    plt.legend()
    plt.show()

fine_tuned_embedding_columns = [
    'markuplm_embedding_base_trained_embedding',
    'markuplm_embedding_large_trained_embedding',
    'visual_embedding_trained_embedding',
    'homepage2vec_embedding_trained_embedding',
    'homepage2vec_withvisual_embedding_trained_embedding',
    'header_embedding_trained_embedding'
]

prediction_of_fine_tuned_embedding_columns = [
    'markuplm_embedding_base_trained_predictions',
    'markuplm_embedding_large_trained_predictions',
    'visual_embedding_trained_predictions',
    'homepage2vec_embedding_trained_predictions',
    'homepage2vec_withvisual_embedding_trained_predictions',
    'header_embedding_trained_predictions'
]

original_label = 'y'

# Colors for each combination of label and prediction
colors = ['blue', 'green', 'red', 'purple']

# Iterate over embedding columns and their corresponding prediction columns
for embedding_column, prediction_column in zip(fine_tuned_embedding_columns, prediction_of_fine_tuned_embedding_columns):
    print("t_SNE for the following embedding: ", embedding_column)
    embeddings = np.array(df[embedding_column].tolist())

    # Calculate metrics
    y_true = df[original_label]
    y_pred = df[prediction_column]
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    print(f"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}")

    # PCA for dimensionality reduction
    pca = PCA(n_components=50)  # Reduce to 50 dimensions for faster t-SNE computation
    pca_result = pca.fit_transform(embeddings)

    # t-SNE for visualization
    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
    tsne_results = tsne.fit_transform(pca_result)

    # Prepare plot
    plt.figure(figsize=(16,10))
    legend_handles = []
    for i, (label, pred) in enumerate(product([0, 1], repeat=2)):
        idx = (df[original_label] == label) & (df[prediction_column] == pred)
        scatter = plt.scatter(tsne_results[idx, 0], tsne_results[idx, 1], color=colors[i], label=f'Label: {label}, Pred: {pred}', alpha=0.5)
        legend_handles.append(scatter)

    plt.title(f't-SNE visualization of {embedding_column}\nAccuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')
    plt.xlabel('t-SNE axis 1')
    plt.ylabel('t-SNE axis 2')
    plt.legend(handles=legend_handles)
    plt.show()

# # Additional suggestions:
# # - Removing duplicates
# df = df.drop_duplicates()

# # - Filling or dropping NA values depending on the column importance
# df.fillna({'some_column': 'default_value'}, inplace=True)
# df.dropna(subset=['important_column'], inplace=True)

# # - Convert columns to appropriate data types (if necessary)
# df['id'] = df['id'].astype(str)

# # - Extracting domain from URL for analysis
# df['extracted_domain'] = df['url'].apply(lambda x: x.split('/')[2] if pd.notna(x) else x)

# # - Analyzing or visualizing embeddings (e.g., using dimensionality reduction techniques like PCA or t-SNE for visualization)

"""# USL

## USL dataset
"""

# Assume df is your DataFrame
usl_dataset = pd.DataFrame({
    'website_embedding_tensors': data['markuplm_embedding_large_trained_embedding'],
    'label': data['y']
})

usl_dataset.head(2)

usl_dataset.info

"""## USL Implementation

To implement the Unsupervised Selective Labeling (USL) on our dataset with embedding vectors, we need to follow these general steps, adapted from the paper's' code:

    1-Load the dataset of embeddings and convert them into a suitable format for PyTorch.
    2-Apply a clustering algorithm, such as K-Means, to identify dense regions and select representative samples
    based on K-NN inside each cluster. K-NN helps with Inter-Cluster Information Exchange
    3-Use a regularizer to ensure diversity among the selected samples in between the clusters.
    4-Fine-tune an SSL model on the selected labeled samples and the remaining unlabeled data.

In this code, we perform K-Means clustering, calculate distances, select the most representative instances based on those distances, and then iteratively apply a regularization step to ensure diversity among the selected instances. The alpha hyperparameter controls how much the diversity affects the selection and may need to be tuned for our dataset.

We might also need to ensure that your embeddings are correctly loaded and that their format is suitable for the cdist function (which expects a 2D array-like structure).


"""

print(type(data['markuplm_embedding_large_trained_embedding'].iloc[0]))

print(type(data['markuplm_embedding_large_trained_embedding'].iloc[0][0]))

print(type(data['y'].iloc[0]))

embeddings = np.array(data['markuplm_embedding_large_trained_embedding'].tolist())  # convert string lists to actual lists
labels = data['y'].tolist()

len(data['markuplm_embedding_large_trained_embedding'].iloc[0])

len(labels)

"""### Density Estimation & Regularizaton

1- We compute the density using the K-nearest neighbors (K-NN) density estimation.

2- We use an exponential moving average (EMA) to update the regularization term.

3- We implement a utility function that balances between the density and the regularization term.



We will need to fine-tune hyperparameters like k, m_reg, alpha, lambda_, and epsilon to ensure the best performance for our specific scenario.
"""

# Step 2 and Step 3: Kmeans, KNN and regularization:
def density_reg(embeddings,n_clusters=5,n_init = 10,m_reg = 0.9,k = 10,lambda_ = 0.5,epsilon=1e-5,alpha=0.5):
  # Parameters
  # n_clusters # set number of clusters
  # n_init # set number of initializations for stability
  # m_reg # Momentum for EMA
  # k  # Number of nearest neighbors for density estimation
  # lambda_   # Balance hyperparameter for utility function

  # K-Means clustering to partition the dataset into clusters
  kmeans = KMeans(n_clusters=n_clusters, n_init=n_init).fit(embeddings)
  cluster_labels = kmeans.labels_
  centroids = kmeans.cluster_centers_
  # print(centroids)

  # Calculate the pairwise distance matrix between embeddings and centroids
  distances = cdist(embeddings, centroids, 'euclidean')
  closest_clusters = np.argmin(distances, axis=1)

  # Regularization term with EMA

  regularization_term = np.zeros(n_clusters)  # Initialize the regularization term for each cluster

  # Initialize the selected indices for each cluster
  selected_indices = np.zeros(n_clusters, dtype=int)

  # Perform the selection process
  for iteration in range(10):
      new_selection = []
      for cluster_index in range(n_clusters):
          cluster_member_indices = np.where(closest_clusters == cluster_index)[0]
          cluster_distances = distances[cluster_member_indices, cluster_index]

          # Density peak selection using K-NN density estimation

          density = 1 / (np.sort(cluster_distances)[:k].mean() + epsilon)

          # Select the instance with the maximum density peak (minimum distance)
          density_peak_index = cluster_member_indices[np.argmax(density)]

          # In the first iteration, we don't have selected_indices for all clusters yet
          if iteration > 0:
              # Exclude the current cluster's selection from all selections
              other_indices = np.delete(selected_indices, cluster_index)

              # Calculate regularization term with EMA
              if other_indices.size > 0:
                  inter_cluster_distances = cdist(embeddings[density_peak_index].reshape(1, -1),
                                                  embeddings[other_indices].reshape(-1, embeddings.shape[1]),
                                                  'euclidean')
                  current_reg_term = np.sum(1 / (inter_cluster_distances ** alpha + epsilon))
                  regularization_term[cluster_index] = m_reg * regularization_term[cluster_index] + \
                                                      (1 - m_reg) * current_reg_term

          # Utility function to guide the selection within each cluster
          lambda_ = 0.5  # Balance hyperparameter for utility function
          utility = density - lambda_ * regularization_term[cluster_index]

          # Selection based on utility
          new_selection_index = cluster_member_indices[np.argmax(utility)]
          new_selection.append(new_selection_index)

      selected_indices = np.array(new_selection)

  # Find indices of points closest to centroids (i.e., cluster centers)
  cluster_center_indices = np.argmin(distances, axis=0)

  print("These are final selections: ",selected_indices)
  return selected_indices,cluster_center_indices,closest_clusters

def find_duplicates(input_list):
    seen = set()
    duplicates = set()
    for item in input_list:
        if item in seen:
            duplicates.add(item)
        else:
            seen.add(item)
    return list(duplicates)

n_clusters=100

# Assuming 'density_reg' is a function that applies your USL method and returns selected indices
# And 'find_duplicates' is a function that finds duplicate values inside a list
train_data=data.loc[data['dataset']=='train']
val_data=data.loc[data['dataset']=='val']
test_data=data.loc[data['dataset']=='test']

embeddings = np.array(train_data['markuplm_embedding_large'].tolist())  # convert string lists to actual lists
# embeddings = np.array(train_data['markuplm_embedding_large_trained_embedding'].tolist())  # we shouldn't use the fine-tuned version, because that is cheating
labels = train_data['y'].tolist()
embeddings_predictions=train_data['markuplm_embedding_large_trained_predictions'].tolist()
selected_indices,cluster_center_indices,closest_clusters = density_reg(embeddings=embeddings,n_clusters=n_clusters, k=20)
print("Duplicated inside selected Indexes: ", find_duplicates(selected_indices))

len(train_data)

n_clusters=5

# Reduce the dimensionality for visualization
pca = PCA(n_components=2)
embeddings_2d = pca.fit_transform(embeddings)

# Assuming 'density_reg' is a function that applies your USL method and returns selected indices
# And 'find_duplicates' is a function that finds duplicate values inside a list
embeddings = np.array(train_data['markuplm_embedding_large'].tolist())  # convert string lists to actual lists
labels = train_data['y'].tolist()
selected_indices,cluster_center_indices,closest_clusters = density_reg(embeddings=embeddings,n_clusters=n_clusters, k=20)
print("Duplicated inside selected Indexes: ", find_duplicates(selected_indices))

# Define a colormap
cmap = plt.get_cmap('tab20')  # This colormap has 20 distinct colors

# Plot all the points as a scatter plot and color them based on their cluster label
plt.figure(figsize=(10, 8))
for i in range(n_clusters):
    # Plot all points for the cluster
    cluster_points = embeddings_2d[closest_clusters == i]
    # Select a color from the colormap for each cluster
    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {i}', color=cmap(i), alpha=0.5)


# Plot code
plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=closest_clusters, cmap='viridis', alpha=0.5)
selected_points = embeddings_2d[selected_indices]
cluster_center_points = embeddings_2d[cluster_center_indices]
plt.scatter(selected_points[:, 0], selected_points[:, 1], color='red', marker='x', label='Selected Points')
plt.scatter(cluster_center_points[:, 0], cluster_center_points[:, 1], color='black', marker='o', label='Cluster Centers from kmeans')
plt.legend()
plt.show()

n_clusters=100

# Reduce the dimensionality for visualization
pca = PCA(n_components=2)
embeddings_2d = pca.fit_transform(embeddings)

# Assuming 'density_reg' is a function that applies your USL method and returns selected indices
# And 'find_duplicates' is a function that finds duplicate values inside a list
embeddings = np.array(train_data['markuplm_embedding_large'].tolist())  # convert string lists to actual lists
labels = train_data['y'].tolist()
selected_indices,cluster_center_indices,closest_clusters = density_reg(embeddings=embeddings,n_clusters=n_clusters, k=20)
print("Duplicated inside selected Indexes: ", find_duplicates(selected_indices))

# Plot all embeddings in the background
plt.figure(figsize=(10, 8))
plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.5, label='All Points')

# Highlight the selected points
selected_points = embeddings_2d[selected_indices]
plt.scatter(selected_points[:, 0], selected_points[:, 1], color='red', marker='x', label='Selected Points', s=100)  # Increase marker size for visibility

# If you have computed cluster centers and want to plot them, do it here.
# Example (assuming 'cluster_centers_2d' contains your PCA-reduced cluster centers):
# plt.scatter(cluster_centers_2d[:, 0], cluster_centers_2d[:, 1], color='black', marker='o', label='Cluster Centers')

plt.legend()
plt.title('PCA Projection of Embeddings')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()

"""# SSL(Mix Match)

Implementing the mixmatch function involves several steps. The function must generate soft pseudo-labels for the unlabeled data, mix the labeled and pseudo-labeled data, and then output the mixed dataset for training.
In this implementation, augment_embeddings adds Gaussian noise to the embeddings, which could be seen as a form of augmentation. The

mixmatch function takes unlabeled data and applies this augmentation K times, predicting the outputs each time. These outputs are then averaged to create the pseudo-labels used for training.
"""

# # USL:
# n_clusters=100

# Assuming 'density_reg' is a function that applies your USL method and returns selected indices
# And 'find_duplicates' is a function that finds duplicate values inside a list
train_data=data.loc[data['dataset']=='train']
val_data=data.loc[data['dataset']=='val']
test_data=data.loc[data['dataset']=='test']

embeddings_train = np.array(train_data['markuplm_embedding_large'].tolist())  # convert string lists to actual lists
# embeddings = np.array(train_data['markuplm_embedding_large_trained_embedding'].tolist())  # we shouldn't use the fine-tuned version, because that is cheating
labels_train = train_data['y'].tolist()
embeddings_predictions_train=train_data['markuplm_embedding_large_trained_predictions'].tolist()

selected_indices

embeddings_train.shape

len(labels_train)

# Define your neural network architecture
class EmbeddingClassifier(nn.Module):
    def __init__(self, embedding_dim, num_classes):
        super(EmbeddingClassifier, self).__init__()
        self.fc1 = nn.Linear(embedding_dim, 256)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x

#SSL




# Custom loss function for soft targets
def kl_divergence_loss(outputs, targets):
    # Ensure outputs are log-probabilities
    log_probabilities = F.log_softmax(outputs, dim=1)
    # Instantiate KLDivLoss
    loss_fn = nn.KLDivLoss(reduction='batchmean')
    # Compute the KL divergence loss
    return loss_fn(log_probabilities, targets)


def sharpen(p, T):
    # Sharpens the distribution by raising it element-wise to the power of 1/T and re-normalizing
    temp = p ** (1 / T)
    return temp / temp.sum(dim=1, keepdim=True)

def mixup(x, y, alpha=0.75):
    # Mixup creates a convex combination of pairs of examples and their labels
    batch_size = x.size(0)
    indices = torch.randperm(batch_size).to(x.device)

    x_mix = x * alpha + x[indices] * (1 - alpha)
    y_mix = y * alpha + y[indices] * (1 - alpha)
    return x_mix, y_mix


def augment_embeddings(embeddings, std_dev=0.1):
    # Add Gaussian noise to the embeddings as a form of augmentation
    noise = torch.randn_like(embeddings) * std_dev
    return embeddings + noise

def mixmatch(labeled_data, labels, unlabeled_data, model, T=0.5, alpha=0.75, K=2, std_dev=0.1):
    model.eval()
    batch_size = unlabeled_data.size(0)

    # Step 1: Augment unlabeled data K times and predict to get soft pseudo-labels
    all_outputs = []
    for _ in range(K):
        aug_unlabeled_data = augment_embeddings(unlabeled_data, std_dev)
        outputs_unlabeled = model(aug_unlabeled_data)
        all_outputs.append(outputs_unlabeled)

    # Average the predictions across augmentations
    avg_outputs_unlabeled = torch.mean(torch.stack(all_outputs), dim=0)
    pseudo_labels = sharpen(torch.softmax(avg_outputs_unlabeled, dim=1), T)

     # Ensure labels are in a compatible format for concatenation
    # Assuming 'num_classes' is defined and accessible
    labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()

    # Step 2: Mix labeled and unlabeled data by applying Mixup
    # Concatenate for Mixup
    all_inputs = torch.cat([labeled_data, unlabeled_data], dim=0)
    all_targets = torch.cat([labels_one_hot, pseudo_labels], dim=0)

    mixed_inputs, mixed_labels = mixup(all_inputs, all_targets, alpha)

    return mixed_inputs, mixed_labels


# Set random seed for reproducibility
torch.manual_seed(0)
if torch.cuda.is_available():
    torch.cuda.manual_seed(0)
    device = 'cuda'
else:
    device = 'cpu'



# Hyperparameters
num_epochs = 10000
input_dim = embeddings_train.shape[1]  # Dynamically assign input_dim
num_classes = len(np.unique(labels))  # Assuming labels are encoded as class indices

# Mix Match
def apply_mixmatch(labeled_loader, unlabeled_loader, model, device, optimizer, num_epochs):
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        unlabeled_iter = iter(unlabeled_loader)  # Create an iterator for the unlabeled data
        for labeled_batch in labeled_loader:
            try:
                unlabeled_batch = next(unlabeled_iter)
            except StopIteration:
                # If unlabeled_loader is exhausted, recreate the iterator
                unlabeled_iter = iter(unlabeled_loader)
                unlabeled_batch = next(unlabeled_iter)

            labeled_data, labels = labeled_batch
            unlabeled_data = unlabeled_batch[0]  # Only get the data, no labels to unpack

            # Move data to the device
            labeled_data = labeled_data.to(device)
            labels = labels.to(device)
            unlabeled_data = unlabeled_data.to(device)

            # Apply MixMatch
            mixed_inputs, mixed_labels = mixmatch(labeled_data, labels, unlabeled_data, model, T=0.5, alpha=0.75, K=2, std_dev=0.1)
            mixed_inputs = mixed_inputs.to(device)
            mixed_labels = mixed_labels.to(device)

            # Forward pass
            outputs = model(mixed_inputs)
            loss = kl_divergence_loss(outputs, mixed_labels)
            total_loss += loss.item()

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(labeled_loader)}')

# Preparing DataLoaders from the USL step
# Assuming `labeled_embeddings`, `unlabeled_embeddings`, and `labels` are ready

# Model Initialization
model = EmbeddingClassifier(input_dim, num_classes).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()  # Might not be directly used if you're sticking with kl_divergence_loss

# Convert embeddings and labels to DataLoader
labeled_embeddings = embeddings_train[selected_indices]
labeled_labels = np.array(labels_train)[selected_indices]  # Ensure labels_train is an array for consistent indexing


all_indices = np.arange(len(embeddings_train))  # Array of all indices
unlabeled_indices = np.setdiff1d(all_indices, selected_indices)  # Exclude selected_indices to get unlabeled ones
unlabeled_embeddings = embeddings_train[unlabeled_indices]
# Convert to tensors and create datasets
labeled_dataset = TensorDataset(torch.tensor(labeled_embeddings, dtype=torch.float32),
                                torch.tensor(labeled_labels, dtype=torch.long))
unlabeled_dataset = TensorDataset(torch.tensor(unlabeled_embeddings, dtype=torch.float32))

# DataLoaders
labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)
unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=True)


# Apply MixMatch
apply_mixmatch(labeled_loader, unlabeled_loader, model, device, optimizer, num_epochs=num_epochs)



# Save the trained model
torch.save(model.state_dict(), 'model_ssl_usl.pth')

"""# USL+SSL vs Finetuned Embeddings prediction"""

import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Set random seed for reproducibility
torch.manual_seed(0)
if torch.cuda.is_available():
    torch.cuda.manual_seed(0)
    device = 'cuda'
else:
    device = 'cpu'


num_labels=2

# Assuming model, val_data, and device are already defined and available
embeddings_val = np.array(val_data['markuplm_embedding_large'].tolist())  # convert string lists to actual lists

# Convert validation embeddings to a tensor and move to the appropriate device
val_embeddings_tensor = torch.tensor(np.array(embeddings_val), dtype=torch.float32).to(device)

#Reading the model:
model = EmbeddingClassifier(embeddings_val.shape[1], num_labels)
model_state_dict = torch.load('model_ssl_usl.pth')
model.load_state_dict(model_state_dict)
model.to(device)

model.eval()  # Set the model to evaluation mode
with torch.no_grad():
    # Obtain model predictions
    val_outputs = model(val_embeddings_tensor)
    # Convert softmax outputs to predicted class indices
    val_predictions_usl_ssl = torch.argmax(val_outputs, dim=1).cpu().numpy()

# True labels for validation data
val_labels = np.array(val_data['y'].tolist())

# Calculate evaluation metrics for the USL+SSL method
accuracy_usl_ssl = accuracy_score(val_labels, val_predictions_usl_ssl)
precision_usl_ssl = precision_score(val_labels, val_predictions_usl_ssl, average='weighted')
recall_usl_ssl = recall_score(val_labels, val_predictions_usl_ssl, average='weighted')
f1_usl_ssl = f1_score(val_labels, val_predictions_usl_ssl, average='weighted')

print(f"USL+SSL Method - Validation Accuracy: {accuracy_usl_ssl}")
print(f"USL+SSL Method - Validation Precision: {precision_usl_ssl}")
print(f"USL+SSL Method - Validation Recall: {recall_usl_ssl}")
print(f"USL+SSL Method - Validation F1 Score: {f1_usl_ssl}")

# Add the calculations for the baseline method if needed, ensuring val_predictions are processed correctly for comparison
# Validation

# True labels
val_labels = np.array(val_data['y'].tolist())

# Predict on the validation data for Baseline
val_embeddings = np.array(val_data['markuplm_embedding_large_trained_embedding'].tolist())
val_predictions = val_data['markuplm_embedding_large_trained_predictions'].tolist()


# Calculate and print the evaluation metrics
accuracy = accuracy_score(val_labels, val_predictions)
precision = precision_score(val_labels, val_predictions, average='weighted')
recall = recall_score(val_labels, val_predictions, average='weighted')
f1 = f1_score(val_labels, val_predictions, average='weighted')

print(f"Validation Accuracy: {accuracy}")
print(f"Validation Precision: {precision}")
print(f"Validation Recall: {recall}")
print(f"Validation F1 Score: {f1}")

# Metrics
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
baseline_values = [accuracy, precision, recall, f1]
usl_ssl_values = [accuracy_usl_ssl, precision_usl_ssl, recall_usl_ssl, f1_usl_ssl]

x = range(len(metrics))  # the label locations

fig, ax = plt.subplots()
ax.bar(x, baseline_values, width=0.4, label='Baseline', align='center')
ax.bar(x, usl_ssl_values, width=0.4, label='USL+SSL', align='edge')

# Add some text for labels, title, and custom x-axis tick labels, etc.
ax.set_ylabel('Scores')
ax.set_title('Performance Comparison')
ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.legend()

plt.show()

# Calculating percentages of baseline reached
percentage_of_baseline = {
    "Accuracy": (accuracy_usl_ssl / accuracy) * 100,
    "Precision": (precision_usl_ssl / precision) * 100,
    "Recall": (recall_usl_ssl / recall) * 100,
    "F1 Score": (f1_usl_ssl / f1) * 100
}

# Preparing data for DataFrame
data = {
    "Metric": ["Accuracy", "Precision", "Recall", "F1 Score"],
    "Baseline": [accuracy, precision, recall, f1],
    "USL+SSL": [accuracy_usl_ssl, precision_usl_ssl, recall_usl_ssl, f1_usl_ssl],
    "Percentage of Baseline": [percentage_of_baseline["Accuracy"], percentage_of_baseline["Precision"], percentage_of_baseline["Recall"], percentage_of_baseline["F1 Score"]]
}

# Creating DataFrame
df = pd.DataFrame(data)

# Formatting for nicer display
df_formatted = df.copy()
df_formatted['Baseline'] = df_formatted['Baseline'].map('{:,.2f}%'.format)
df_formatted['USL+SSL'] = df_formatted['USL+SSL'].map('{:,.2f}%'.format)
df_formatted['Percentage of Baseline'] = df_formatted['Percentage of Baseline'].map('{:,.2f}%'.format)

# Display DataFrame
print(df_formatted)


df.to_html("comparison_report.html")


print("The comparison report has been saved to 'comparison_report_usl.html'.")