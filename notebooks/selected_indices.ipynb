{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from src.models.ssl_models_curlie import embedding_classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, hamming_loss, precision_score, recall_score,accuracy_score\n",
    "# from torch import cdist\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from src.models.ssl_models_curlie.embedding_classifier import EmbeddingClassifier\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "from torch import nn, optim\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"../data_curlie/processed/selected_indices_sampled.pkl\"\n",
    "try:\n",
    "    with open(filepath, 'rb') as file:\n",
    "        selected_indices_sampled = pickle.load(file)\n",
    "except Exception as e:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   387,    158,   1023,   1420,      4,   1181,   9167,    149,\n",
       "          215,   1426,   3143,   6009,   1274,   4069,   5117,    207,\n",
       "          145,    440,   8922,   1362,    136,   6622,    772,  11855,\n",
       "          193,    186,     36,    444,    237,     47,   1130,     13,\n",
       "          389,     44,    719,     24,    386,     74,    416, 528961,\n",
       "        29078,   6616,   5230,      6,   2645,    583,    574,     62,\n",
       "        90431,   1179,    124,    708,    621,     61,   2362,      1,\n",
       "          654,      8,    506,  17438,    458,    398,     19,   1470,\n",
       "           34,   4108,     75,    477,    348,    994,   5569,    694,\n",
       "          879,    577,      0,    159,    210,   1158,    261,   2920,\n",
       "         6032,   1444,    585,   8099,   7131,    904,    457,    196,\n",
       "           16,    119,     11,    461,    181,      3,   2268,    374,\n",
       "        24871,   4722,     64,    625,     33,     14,    135,     45,\n",
       "         1631,   9271,    162,   3629,    763,     22,    412,   1265,\n",
       "          947,   6447,   2853,   7405,     48,   1921,    858,    764,\n",
       "          867,  17744,    156,    381,   1301,     29,    189,    377,\n",
       "          185,    922,   6399,    930,   3231,   5994,    148,    262,\n",
       "          102,   1133,    635,    211,    418,   2634,   5603,    298,\n",
       "          111,     27,   6077,   5846,     10,   6116,   1167,   1307,\n",
       "         8768,      2,   2681,   5998,    134,   3626,     60,     90,\n",
       "          974,   2707,      7,   1457,    945,   1055,    411,   4028,\n",
       "         1136,   1375,   2070,   4527,    150,   1102,    902,   5738,\n",
       "          407,    472,    877,    100,   5840,    429,    328,    463,\n",
       "          132,    932,    371,    153,    160,   1088,    183,    843,\n",
       "          691,    171,    556,     51,    214,    368,   4621,   4774,\n",
       "         1145,     67,     12,     92,    885,     71,    140,   1254,\n",
       "          483,    319,   2594,    147,     55,   1392,     26,   4057,\n",
       "         1391,    436,   9200,     56,   1462,    120,   4423,    420,\n",
       "          123,     37,     80,   3497,   7119,   4783,   1176,   1183,\n",
       "         3141,     38,    117,    128,     84,   6047,    525,    530,\n",
       "          121,   1035,     77,    503,   1182,   5517,   3354,    402,\n",
       "          415,   3227,  13248,     20,     35,     32,     46,     30,\n",
       "         1219,    540,   1473,    604,    487,    396,    174,     88,\n",
       "         5781,    413,    322,    408,   3531,  12844,    143,   7193,\n",
       "          881,     97,  12339,     54,    946,   1269,    188,    105,\n",
       "         3457,  17553,   2844,    272,   6071,    383,    400,   4746,\n",
       "         1361,   1296,   1397,    736,    478,     25,      5,    125,\n",
       "           31,     66,    126,    460])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_indices_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_indices_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"../data_curlie/processed/train_sampled.pkl\"\n",
    "try:\n",
    "    with open(filepath, 'rb') as file:\n",
    "        train_sampled = pickle.load(file)\n",
    "except Exception as e:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>header_embeddings</th>\n",
       "      <th>url</th>\n",
       "      <th>h2v_pred</th>\n",
       "      <th>h2v_embedding</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143215</td>\n",
       "      <td>[-0.12137477099895477, 0.3743447065353393, 0.0...</td>\n",
       "      <td>www.sg-adelsberg.de</td>\n",
       "      <td>[0.0006075641140341759, 0.003006806131452322, ...</td>\n",
       "      <td>[-2.8622231483459473, 1.2275725603103638, 1.04...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>657885</td>\n",
       "      <td>[-0.04726717248558998, 0.0948432385921478, 0.1...</td>\n",
       "      <td>www.myguitarsolo.com</td>\n",
       "      <td>[0.9886903166770935, 0.011595186777412891, 0.0...</td>\n",
       "      <td>[1.731790542602539, 2.1384191513061523, -1.021...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>973532</td>\n",
       "      <td>[-0.01860016956925392, 0.3559060394763946, 0.2...</td>\n",
       "      <td>www.factoryfive.com</td>\n",
       "      <td>[0.014509319327771664, 0.6098007559776306, 0.0...</td>\n",
       "      <td>[-0.6853832602500916, 0.21162883937358856, 0.3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1112170</td>\n",
       "      <td>[-0.044978976249694824, 0.2400597184896469, 0....</td>\n",
       "      <td>www.socalkees.org</td>\n",
       "      <td>[9.662981028668582e-07, 0.003199808532372117, ...</td>\n",
       "      <td>[-2.572124719619751, 0.4726077616214752, 3.399...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>986375</td>\n",
       "      <td>[-0.0047127907164394855, 0.1424452066421508, 0...</td>\n",
       "      <td>www.vordingborgswim.dk</td>\n",
       "      <td>[0.008630601689219475, 0.013073411770164967, 0...</td>\n",
       "      <td>[-2.650256872177124, 0.7773601412773132, 1.352...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>1975649</td>\n",
       "      <td>[0.19816362857818604, 0.2595343589782715, -0.1...</td>\n",
       "      <td>unimex-bg.com</td>\n",
       "      <td>[0.3214002549648285, 0.7721798419952393, 0.088...</td>\n",
       "      <td>[0.9274794459342957, 0.14115266501903534, -0.2...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>1019643</td>\n",
       "      <td>[0.06207523122429848, 0.2220538854598999, -0.0...</td>\n",
       "      <td>www.web.de</td>\n",
       "      <td>[0.1325898915529251, 0.16243311762809753, 0.97...</td>\n",
       "      <td>[1.8066908121109009, 1.5915579795837402, -1.12...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>1458708</td>\n",
       "      <td>[0.013551934622228146, -0.3369513154029846, 0....</td>\n",
       "      <td>www.cetir.com</td>\n",
       "      <td>[0.02369690127670765, 0.3997385501861572, 0.08...</td>\n",
       "      <td>[1.3136509656906128, -1.272384762763977, 0.524...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>613223</td>\n",
       "      <td>[0.032556768506765366, 0.0402247346937656, 0.0...</td>\n",
       "      <td>www.wouf.net</td>\n",
       "      <td>[0.1965414583683014, 0.09160946309566498, 0.03...</td>\n",
       "      <td>[-0.19722652435302734, 1.7930998802185059, 1.6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>539193</td>\n",
       "      <td>[-0.1407049000263214, 0.0497642941772937, 0.21...</td>\n",
       "      <td>kodai.linksmai.lt</td>\n",
       "      <td>[0.40637707710266113, 0.27072635293006897, 0.9...</td>\n",
       "      <td>[0.4721812605857849, 1.347215175628662, -1.808...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid                                  header_embeddings  \\\n",
       "0       143215  [-0.12137477099895477, 0.3743447065353393, 0.0...   \n",
       "1       657885  [-0.04726717248558998, 0.0948432385921478, 0.1...   \n",
       "2       973532  [-0.01860016956925392, 0.3559060394763946, 0.2...   \n",
       "3      1112170  [-0.044978976249694824, 0.2400597184896469, 0....   \n",
       "4       986375  [-0.0047127907164394855, 0.1424452066421508, 0...   \n",
       "...        ...                                                ...   \n",
       "10995  1975649  [0.19816362857818604, 0.2595343589782715, -0.1...   \n",
       "10996  1019643  [0.06207523122429848, 0.2220538854598999, -0.0...   \n",
       "10997  1458708  [0.013551934622228146, -0.3369513154029846, 0....   \n",
       "10998   613223  [0.032556768506765366, 0.0402247346937656, 0.0...   \n",
       "10999   539193  [-0.1407049000263214, 0.0497642941772937, 0.21...   \n",
       "\n",
       "                          url  \\\n",
       "0         www.sg-adelsberg.de   \n",
       "1        www.myguitarsolo.com   \n",
       "2         www.factoryfive.com   \n",
       "3           www.socalkees.org   \n",
       "4      www.vordingborgswim.dk   \n",
       "...                       ...   \n",
       "10995           unimex-bg.com   \n",
       "10996              www.web.de   \n",
       "10997           www.cetir.com   \n",
       "10998            www.wouf.net   \n",
       "10999       kodai.linksmai.lt   \n",
       "\n",
       "                                                h2v_pred  \\\n",
       "0      [0.0006075641140341759, 0.003006806131452322, ...   \n",
       "1      [0.9886903166770935, 0.011595186777412891, 0.0...   \n",
       "2      [0.014509319327771664, 0.6098007559776306, 0.0...   \n",
       "3      [9.662981028668582e-07, 0.003199808532372117, ...   \n",
       "4      [0.008630601689219475, 0.013073411770164967, 0...   \n",
       "...                                                  ...   \n",
       "10995  [0.3214002549648285, 0.7721798419952393, 0.088...   \n",
       "10996  [0.1325898915529251, 0.16243311762809753, 0.97...   \n",
       "10997  [0.02369690127670765, 0.3997385501861572, 0.08...   \n",
       "10998  [0.1965414583683014, 0.09160946309566498, 0.03...   \n",
       "10999  [0.40637707710266113, 0.27072635293006897, 0.9...   \n",
       "\n",
       "                                           h2v_embedding  \\\n",
       "0      [-2.8622231483459473, 1.2275725603103638, 1.04...   \n",
       "1      [1.731790542602539, 2.1384191513061523, -1.021...   \n",
       "2      [-0.6853832602500916, 0.21162883937358856, 0.3...   \n",
       "3      [-2.572124719619751, 0.4726077616214752, 3.399...   \n",
       "4      [-2.650256872177124, 0.7773601412773132, 1.352...   \n",
       "...                                                  ...   \n",
       "10995  [0.9274794459342957, 0.14115266501903534, -0.2...   \n",
       "10996  [1.8066908121109009, 1.5915579795837402, -1.12...   \n",
       "10997  [1.3136509656906128, -1.272384762763977, 0.524...   \n",
       "10998  [-0.19722652435302734, 1.7930998802185059, 1.6...   \n",
       "10999  [0.4721812605857849, 1.347215175628662, -1.808...   \n",
       "\n",
       "                                            label dataset  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   train  \n",
       "1      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   train  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   train  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   train  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   train  \n",
       "...                                           ...     ...  \n",
       "10995  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   train  \n",
       "10996  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   train  \n",
       "10997  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   train  \n",
       "10998  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   train  \n",
       "10999  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   train  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.12137477099895477, 0.3743447065353393, 0.0...\n",
       "1        [-0.04726717248558998, 0.0948432385921478, 0.1...\n",
       "2        [-0.01860016956925392, 0.3559060394763946, 0.2...\n",
       "3        [-0.044978976249694824, 0.2400597184896469, 0....\n",
       "4        [-0.0047127907164394855, 0.1424452066421508, 0...\n",
       "                               ...                        \n",
       "10995    [0.19816362857818604, 0.2595343589782715, -0.1...\n",
       "10996    [0.06207523122429848, 0.2220538854598999, -0.0...\n",
       "10997    [0.013551934622228146, -0.3369513154029846, 0....\n",
       "10998    [0.032556768506765366, 0.0402247346937656, 0.0...\n",
       "10999    [-0.1407049000263214, 0.0497642941772937, 0.21...\n",
       "Name: header_embeddings, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings=train_sampled['header_embeddings']\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(0)\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    print(\"Device: \", device)\n",
    "    return device\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the USL SSL model...\n",
      "Device:  cuda\n",
      "Input dimension:  767\n",
      "Number of classes:  14\n",
      "\n",
      "Class Frequencies:\n",
      " label0     0.0956\n",
      "label1     0.2836\n",
      "label2     0.0611\n",
      "label3     0.0183\n",
      "label4     0.0623\n",
      "label5     0.0141\n",
      "label6     0.0115\n",
      "label7     0.0112\n",
      "label8     0.0869\n",
      "label9     0.0446\n",
      "label10    0.0460\n",
      "label11    0.0797\n",
      "label12    0.1399\n",
      "label13    0.0677\n",
      "dtype: float64\n",
      "Epoch 1, Loss: 0.05223982025436155\n",
      "Epoch 2, Loss: 0.01634586414998504\n",
      "Epoch 3, Loss: 0.016176146787300612\n",
      "Epoch 4, Loss: 0.016098297076525204\n",
      "Epoch 5, Loss: 0.01602807333159029\n",
      "Epoch 6, Loss: 0.015969539547611954\n",
      "Epoch 7, Loss: 0.015950796413858225\n",
      "Epoch 8, Loss: 0.015858007689854903\n",
      "Epoch 9, Loss: 0.015774582103369343\n",
      "Epoch 10, Loss: 0.01576668164058096\n",
      "Epoch 11, Loss: 0.01561252541460429\n",
      "Epoch 12, Loss: 0.015528230138929787\n",
      "Epoch 13, Loss: 0.015382328563055415\n",
      "Epoch 14, Loss: 0.015226261215699706\n",
      "Epoch 15, Loss: 0.01511301648963219\n",
      "Epoch 16, Loss: 0.014930134639143944\n",
      "Epoch 17, Loss: 0.01478028913164974\n",
      "Epoch 18, Loss: 0.014540966001048589\n",
      "Epoch 19, Loss: 0.014400625779370593\n",
      "Epoch 20, Loss: 0.014225220194999959\n",
      "Epoch 21, Loss: 0.013909867448601752\n",
      "Epoch 22, Loss: 0.013802559921743384\n",
      "Epoch 23, Loss: 0.013539094021128621\n",
      "Epoch 24, Loss: 0.013226894299932726\n",
      "Epoch 25, Loss: 0.01295735134749086\n",
      "Epoch 26, Loss: 0.012840109230701332\n",
      "Epoch 27, Loss: 0.012491315799011925\n",
      "Epoch 28, Loss: 0.01241106147860076\n",
      "Epoch 29, Loss: 0.012100497456445435\n",
      "Epoch 30, Loss: 0.011870090303954426\n",
      "Epoch 31, Loss: 0.011734481705174705\n",
      "Epoch 32, Loss: 0.011639858186719525\n",
      "Epoch 33, Loss: 0.011387014809023044\n",
      "Epoch 34, Loss: 0.011212487746575836\n",
      "Epoch 35, Loss: 0.010957861823403532\n",
      "Epoch 36, Loss: 0.010861678387091797\n",
      "Epoch 37, Loss: 0.010562673139913827\n",
      "Epoch 38, Loss: 0.010524223481488836\n",
      "Epoch 39, Loss: 0.01043509929233296\n",
      "Epoch 40, Loss: 0.010269505220945854\n",
      "Epoch 41, Loss: 0.00986451315130018\n",
      "Epoch 42, Loss: 0.009720605175206615\n",
      "Epoch 43, Loss: 0.0096352639708929\n",
      "Epoch 44, Loss: 0.00958441227828716\n",
      "Epoch 45, Loss: 0.009293152846894257\n",
      "Epoch 46, Loss: 0.009052486642364674\n",
      "Epoch 47, Loss: 0.008957616700108643\n",
      "Epoch 48, Loss: 0.008693705633235205\n",
      "Epoch 49, Loss: 0.008452420300881194\n",
      "Epoch 50, Loss: 0.008484301439065273\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the USL SSL model...\")\n",
    "\n",
    "device = get_device()\n",
    "labels=train_sampled['label']\n",
    "input_dim = 767\n",
    "print(\"Input dimension: \", input_dim)\n",
    "num_classes = 14  # Assuming labels are one-hot encoded\n",
    "print(\"Number of classes: \", num_classes)\n",
    "\n",
    "\n",
    "# Assuming EmbeddingClassifier is a defined model suitable for your needs\n",
    "model = EmbeddingClassifier(input_dim, num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Analyzing class imbalance\n",
    "labels=np.array(labels.tolist())\n",
    "df_labels = pd.DataFrame(labels, columns=[f\"label{i}\" for i in range(labels.shape[1])])\n",
    "class_frequencies = df_labels.mean()  # Proportion of positive instances for each label\n",
    "print(\"\\nClass Frequencies:\\n\", class_frequencies)\n",
    "\n",
    "# Assuming 'class_frequencies' is a Pandas Series from your previous message\n",
    "weights = (1 / class_frequencies) / (1 / class_frequencies).sum()\n",
    "pos_weight = torch.tensor(weights.values).float().to(device)\n",
    "\n",
    "# Update your loss function to use pos_weight\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "\n",
    "# Preparing DataLoaders\n",
    "labeled_embeddings = embeddings\n",
    "labeled_labels = labels  # Directly use labels without converting to numpy array if already tensor\n",
    "\n",
    "\n",
    "# Convert to tensors and create datasets\n",
    "labeled_dataset = TensorDataset(torch.tensor(labeled_embeddings, dtype=torch.float32),\n",
    "                                torch.tensor(labeled_labels, dtype=torch.float32))\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):  # Number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in labeled_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss / len(labeled_loader)}')\n",
    "\n",
    "    # Implementing a strategy for unlabeled data if needed\n",
    "    # This could involve pseudo-labeling, consistency regularization, etc.\n",
    "\n",
    "# You could add validation steps, model saving, etc., as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"../data_curlie/processed/val_sampled.pkl\"\n",
    "try:\n",
    "    with open(filepath, 'rb') as file:\n",
    "        val_sampled = pickle.load(file)\n",
    "except Exception as e:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val=val_sampled['label'].tolist()\n",
    "embeddings_val=val_sampled['header_embeddings'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the USL SSL model...:  \n",
      "Device:  cuda\n",
      "True labels:  [[0 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "\n",
      "Class Frequencies:\n",
      " label0     0.108\n",
      "label1     0.258\n",
      "label2     0.072\n",
      "label3     0.014\n",
      "label4     0.046\n",
      "label5     0.022\n",
      "label6     0.006\n",
      "label7     0.008\n",
      "label8     0.064\n",
      "label9     0.052\n",
      "label10    0.034\n",
      "label11    0.094\n",
      "label12    0.152\n",
      "label13    0.084\n",
      "dtype: float64\n",
      "Probabilities:\n",
      "tensor([[3.3069e-03, 2.7587e-03, 4.5342e-05,  ..., 2.0535e-04, 1.2115e-03,\n",
      "         7.9171e-03],\n",
      "        [9.6331e-04, 1.2865e-03, 3.0796e-06,  ..., 6.4664e-04, 1.4372e-03,\n",
      "         2.5112e-03],\n",
      "        [1.7975e-03, 2.7533e-03, 5.4590e-05,  ..., 3.9604e-04, 1.7014e-03,\n",
      "         3.2003e-04],\n",
      "        ...,\n",
      "        [2.9790e-03, 1.6150e-04, 7.7408e-03,  ..., 2.2524e-04, 2.0458e-04,\n",
      "         1.3685e-03],\n",
      "        [1.7911e-04, 7.7685e-04, 6.5966e-03,  ..., 1.4853e-04, 1.0234e-03,\n",
      "         8.8540e-04],\n",
      "        [2.6876e-03, 5.8213e-04, 1.0436e-03,  ..., 2.0605e-03, 6.0636e-04,\n",
      "         3.5447e-02]], device='cuda:0')\n",
      "Predictions from the SSL model:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Validation Results:\n",
      "SSL Model - Hamming Loss: 0.07342857142857143, Precision: 0.23076923076923078, Recall: 0.005917159763313609, F1 Score: 0.011538461538461537\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the USL SSL model...:  \")\n",
    "device=get_device()\n",
    "\n",
    "# embeddings_val = min_max_scale_embeddings(embeddings_val)#normalize embeddings\n",
    "\n",
    "# Load the true labels\n",
    "val_labels = np.array(labels_val)\n",
    "print(\"True labels: \",val_labels)\n",
    "\n",
    "\n",
    "# Analyzing class imbalance\n",
    "df_labels = pd.DataFrame(val_labels, columns=[f\"label{i}\" for i in range(val_labels.shape[1])])\n",
    "class_frequencies = df_labels.mean()  # Proportion of positive instances for each label\n",
    "print(\"\\nClass Frequencies:\\n\", class_frequencies)\n",
    "\n",
    "\n",
    "# Predictions from the SSL model\n",
    "val_embeddings_tensor = torch.tensor(np.array(embeddings_val), dtype=torch.float32).to(device)\n",
    "\n",
    "threshold=0.5\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Obtain model predictions (logits)\n",
    "    val_outputs = model(val_embeddings_tensor)\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = torch.sigmoid(val_outputs)\n",
    "    print(\"Probabilities:\")\n",
    "    print(probabilities)\n",
    "    # Apply threshold to get binary predictions for each class\n",
    "    predictions = (probabilities > threshold).int().cpu().numpy()\n",
    "    predictions\n",
    "    \n",
    "print(\"Predictions from the SSL model: \",predictions)\n",
    "\n",
    "# Evaluate SSL-enhanced model\n",
    "hamming_loss_ssl = hamming_loss(val_labels, predictions)\n",
    "precision_ssl = precision_score(val_labels,predictions, average='micro')\n",
    "recall_ssl = recall_score(val_labels, predictions, average='micro')\n",
    "f1_ssl = f1_score(val_labels, predictions, average='micro')\n",
    "\n",
    "# Print results\n",
    "print(\"Validation Results:\")\n",
    "print(f\"SSL Model - Hamming Loss: {hamming_loss_ssl}, Precision: {precision_ssl}, Recall: {recall_ssl}, F1 Score: {f1_ssl}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usl_for_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
